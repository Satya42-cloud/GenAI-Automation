{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "470d8af5-243e-4f21-99e6-653886c33582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mlflow\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "# --- Helper Functions for Quarter Boundaries ---\n",
    "def get_quarter_boundaries(dt: pd.Timestamp):\n",
    "    \"\"\"\n",
    "    Given a datetime dt, returns the start and end date for the quarter in which dt lies.\n",
    "    Quarters: Q1: Jan-Mar, Q2: Apr-Jun, Q3: Jul-Sep, Q4: Oct-Dec.\n",
    "    \"\"\"\n",
    "    year = dt.year\n",
    "    if dt.month <= 3:\n",
    "        return pd.Timestamp(year, 1, 1), pd.Timestamp(year, 3, 31)\n",
    "    elif dt.month <= 6:\n",
    "        return pd.Timestamp(year, 4, 1), pd.Timestamp(year, 6, 30)\n",
    "    elif dt.month <= 9:\n",
    "        return pd.Timestamp(year, 7, 1), pd.Timestamp(year, 9, 30)\n",
    "    else:\n",
    "        return pd.Timestamp(year, 10, 1), pd.Timestamp(year, 12, 31)\n",
    "\n",
    "def next_quarter_bounds(ref_date: pd.Timestamp):\n",
    "    \"\"\"\n",
    "    Given a reference date, returns the start and end dates for the next quarter.\n",
    "    \"\"\"\n",
    "    current_start, current_end = get_quarter_boundaries(ref_date)\n",
    "    next_start = current_end + pd.Timedelta(days=1)\n",
    "    _, next_end = get_quarter_boundaries(next_start)\n",
    "    return next_start, next_end\n",
    "\n",
    "# --- Configuration & Paths ---\n",
    "output_dir = \"/dbfs/FileStore/prophet_forecasts\"      # Directory for forecast CSV files\n",
    "plot_dir = \"/dbfs/FileStore/prophet_plots\"              # Directory for forecast plots\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# Delta table names\n",
    "predictions_delta_table = \"genai_catalog.genai_schema.truck_forecast_predictions\"\n",
    "historical_delta_table = \"genai_catalog.genai_schema.filtered_zone_truck_demand\"\n",
    "routes_delta_table = \"genai_catalog.genai_schema.routes\"\n",
    "\n",
    "# --- Load Data from Delta ---\n",
    "df_hist = spark.table(historical_delta_table).toPandas()\n",
    "df_hist['Date'] = pd.to_datetime(df_hist['Date'])\n",
    "df_hist.rename(columns={'Date': 'ds', 'Count_of_Truck': 'y'}, inplace=True)\n",
    "\n",
    "# --- Load Holidays Data ---\n",
    "# Option A: If you want to use an external holidays table, uncomment and use it;\n",
    "# Otherwise, we will use Prophet's built-in holidays.\n",
    "try:\n",
    "    holidays_df = spark.table(\"genai_catalog.genai_schema.holidays\").toPandas()\n",
    "    holidays_df['ds'] = pd.to_datetime(holidays_df['ds'])\n",
    "except Exception as e:\n",
    "    print(\"Could not load external holidays table. Falling back to empty DataFrame.\")\n",
    "    holidays_df = pd.DataFrame()  # Empty DataFrame, in which case we'll add built-in holidays below\n",
    "\n",
    "# --- Dynamic Date Calculations ---\n",
    "current_date = df_hist['ds'].max()  # Most recent date in historical data\n",
    "train_ratio = 0.8\n",
    "earliest_date = df_hist['ds'].min()\n",
    "total_duration = current_date - earliest_date\n",
    "train_cutoff_date = earliest_date + total_duration * train_ratio\n",
    "\n",
    "df_train = df_hist[df_hist['ds'] <= train_cutoff_date]\n",
    "df_test = df_hist[df_hist['ds'] > train_cutoff_date]\n",
    "\n",
    "# Determine forecast window for the next quarter\n",
    "forecast_start, forecast_end = next_quarter_bounds(current_date)\n",
    "future_dates = pd.date_range(start=forecast_start, end=forecast_end, freq='W-WED')\n",
    "\n",
    "# Build a label for the forecast quarter and a timestamp for file naming\n",
    "forecast_quarter = f\"Q{((forecast_start.month - 1) // 3) + 1}_{forecast_start.year}\"\n",
    "timestamp_str = datetime.now(pytz.utc).strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n",
    "# --- Validate Required Columns in df_hist ---\n",
    "required_cols = {'Route_ID', 'Truck_Type', 'Zone'}\n",
    "if not required_cols.issubset(set(df_hist.columns)):\n",
    "    raise ValueError(\"Historical data must contain 'Route_ID', 'Truck_Type', and 'Zone' columns.\")\n",
    "\n",
    "# Get unique combinations for forecast (per route, truck type, zone)\n",
    "combinations = df_hist[['Route_ID', 'Truck_Type', 'Zone']].drop_duplicates()\n",
    "\n",
    "results = []\n",
    "metrics_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f784d7-cc05-4939-9339-efec99603796",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_registry_uri(\"demand_forecasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50059e39-f3c1-4eaf-84ab-b289aa34e196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm# --- Loop over Each Combination & Forecast ---\n",
    "\n",
    "for _, row in tqdm(combinations.iterrows(), total=combinations.shape[0], desc=\"Forecasting combinations\"):\n",
    "    route = row['Route_ID']\n",
    "    truck_type = row['Truck_Type']\n",
    "    zone = row['Zone']\n",
    "    \n",
    "    combo_df = df_hist[(df_hist['Route_ID'] == route) & (df_hist['Truck_Type'] == truck_type)].copy()\n",
    "    if len(combo_df) < 50:\n",
    "        continue\n",
    "\n",
    "    # Split data using the dynamic cutoff date\n",
    "    train_data = combo_df[combo_df['ds'] <= train_cutoff_date]\n",
    "    test_data = combo_df[combo_df['ds'] > train_cutoff_date]\n",
    "    \n",
    "    # Create the experiment directory if it does not exist\n",
    "    experiment_path = f\"/Workspace/GenAIAutomation/Truck_Demand_Forecasting/{route}_{truck_type}_{forecast_quarter}_{timestamp_str}\"\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_path)\n",
    "    # if experiment is None:\n",
    "    #     mlflow.create_experiment(experiment_path)\n",
    "    mlflow.set_experiment(experiment_path)\n",
    "    \n",
    "    try:\n",
    "        with mlflow.start_run(run_name=f\"{route}_{truck_type}_forecast_{forecast_quarter}_{timestamp_str}\"):\n",
    "            # Initialize Prophet model.\n",
    "            # If external holidays_df is empty, we use built-in country holidays.\n",
    "            model = Prophet(\n",
    "                seasonality_mode='multiplicative',\n",
    "                changepoint_prior_scale=0.1,\n",
    "                seasonality_prior_scale=10.0,\n",
    "                holidays_prior_scale=15.0,\n",
    "                weekly_seasonality=True,\n",
    "                yearly_seasonality=True\n",
    "            )\n",
    "            if holidays_df.empty:\n",
    "                # Use built-in holidays for India as an example; adjust as needed.\n",
    "                model.add_country_holidays(country_name='India')\n",
    "            else:\n",
    "                model.holidays = holidays_df\n",
    "\n",
    "            # Fit the model on the training data.\n",
    "            model.fit(train_data[['ds', 'y']])\n",
    "            \n",
    "            # Evaluate on test data if available.\n",
    "            if not test_data.empty:\n",
    "                future_test = test_data[['ds']].copy()\n",
    "                forecast_test = model.predict(future_test)\n",
    "                y_true = test_data['y'].values\n",
    "                y_pred = forecast_test['yhat'].clip(lower=0).values\n",
    "\n",
    "                mae = mean_absolute_error(y_true, y_pred)\n",
    "                mse = mean_squared_error(y_true, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n",
    "\n",
    "                mlflow.log_metric(\"MAE\", mae)\n",
    "                mlflow.log_metric(\"RMSE\", rmse)\n",
    "                mlflow.log_metric(\"MAPE\", mape)\n",
    "\n",
    "                metrics_list.append({\n",
    "                    'Route_ID': route,\n",
    "                    'Truck_Type': truck_type,\n",
    "                    'Zone': zone,\n",
    "                    'MAE': round(mae, 2),\n",
    "                    'MSE': round(mse, 2),\n",
    "                    'RMSE': round(rmse, 2),\n",
    "                    'MAPE': round(mape, 2),\n",
    "                    'Forecast_Quarter': forecast_quarter\n",
    "                })\n",
    "\n",
    "            # Forecast for the next quarter.\n",
    "            future_forecast = pd.DataFrame({'ds': future_dates})\n",
    "            forecast = model.predict(future_forecast)\n",
    "            forecast['yhat'] = np.ceil(forecast['yhat'].clip(lower=0)).astype(int)\n",
    "            forecast['yhat_lower'] = np.ceil(forecast['yhat_lower'].clip(lower=0)).astype(int)\n",
    "            forecast['yhat_upper'] = np.ceil(forecast['yhat_upper'].clip(lower=0)).astype(int)\n",
    "\n",
    "            forecast_df = pd.DataFrame({\n",
    "                'Date': forecast['ds'],\n",
    "                'Route_ID': route,\n",
    "                'Truck_Type': truck_type,\n",
    "                'Zone': zone,\n",
    "                'Forecasted_Count_of_Truck': forecast['yhat'],\n",
    "                'Lower_Limit': forecast['yhat_lower'],\n",
    "                'Upper_Limit': forecast['yhat_upper'],\n",
    "                'Forecast_Quarter': forecast_quarter,\n",
    "                'Run_Timestamp': timestamp_str\n",
    "            })\n",
    "            results.append(forecast_df)\n",
    "\n",
    "            # Create a plot of the forecast.\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            if not test_data.empty:\n",
    "                plt.plot(test_data['ds'], test_data['y'], label='Actual Test', color='blue')\n",
    "            plt.plot(forecast['ds'], forecast['yhat'], label='Forecast', color='green')\n",
    "            plt.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], \n",
    "                             color='red', alpha=0.2, label='Confidence Interval')\n",
    "            plt.title(f\"Truck Forecast: {route} | {truck_type} - {forecast_quarter}\")\n",
    "            plt.xlabel(\"Date\")\n",
    "            plt.ylabel(\"Truck Count\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "\n",
    "            plot_file = f\"{plot_dir}/{route}_{truck_type}_{forecast_quarter}_{timestamp_str}.png\"\n",
    "            plt.savefig(plot_file)\n",
    "            plt.close()\n",
    "            mlflow.log_artifact(plot_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {route} - {truck_type}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- Save Combined Forecasts ---\n",
    "if results:\n",
    "    forecast_final = pd.concat(results, ignore_index=True)\n",
    "    forecast_csv_name = f\"Forecast_{forecast_quarter}_{timestamp_str}.csv\"\n",
    "    forecast_csv_path = os.path.join(output_dir, forecast_csv_name)\n",
    "    forecast_final.to_csv(forecast_csv_path, index=False)\n",
    "    print(f\"Forecast CSV saved to: {forecast_csv_path}\")\n",
    "    mlflow.log_artifact(forecast_csv_path)\n",
    "else:\n",
    "    print(\"No forecast results generated.\")\n",
    "\n",
    "# --- Write Predictions to Delta Table ---\n",
    "if results:\n",
    "    forecast_sdf = spark.createDataFrame(forecast_final)\n",
    "    from delta.tables import DeltaTable\n",
    "    try:\n",
    "        # Attempt to get Delta table by name; if found, merge records\n",
    "        deltaTable = DeltaTable.forName(spark, predictions_delta_table)\n",
    "        # Use a composite key: Date, Forecast_Quarter, Route_ID, Truck_Type, Zone.\n",
    "        deltaTable.alias(\"tgt\").merge(\n",
    "            forecast_sdf.alias(\"src\"),\n",
    "            \"tgt.Date = src.Date AND tgt.Forecast_Quarter = src.Forecast_Quarter AND tgt.Route_ID = src.Route_ID AND tgt.Truck_Type = src.Truck_Type AND tgt.Zone = src.Zone\"\n",
    "        ).whenMatchedUpdateAll() \\\n",
    "         .whenNotMatchedInsertAll() \\\n",
    "         .execute()\n",
    "    except Exception as ex:\n",
    "        # If table not found, write out as new Delta table.\n",
    "        forecast_sdf.write.format(\"delta\").mode(\"append\").saveAsTable(predictions_delta_table)\n",
    "    \n",
    "    print(f\"Predictions successfully written to Delta table: {predictions_delta_table}\")\n",
    "else:\n",
    "    print(\"No forecast records to write to Delta.\")\n",
    "\n",
    "print(\"All done! Forecasts, evaluation metrics, and Delta table updates complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77aed915-f41b-430e-b62c-b81fcea4082f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "forecast_sdf.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "083da055-e0ce-4fb8-b998-50891c948099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Import Required Packages ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Load Data from Delta Tables ---\n",
    "forecast_df = forecast_sdf.toPandas()\n",
    "route_df = spark.table(\"genai_catalog.genai_schema.multi_stop_route_plan\").toPandas()\n",
    "\n",
    "# --- Clean and Prepare Route Data ---\n",
    "route_df.rename(columns={\n",
    "    'Route ID': 'Route_ID',\n",
    "    'Distance (km)': 'Distance_km',\n",
    "    'Estimated Time (hrs)': 'Estimated_Time_hrs'\n",
    "}, inplace=True)\n",
    "\n",
    "# --- Aggregate Forecast Metrics ---\n",
    "summary_df = (\n",
    "    forecast_df\n",
    "    .groupby(['Route_ID', 'Truck_Type', 'Zone'], as_index=False)\n",
    "    .agg(\n",
    "        Required_Trucks=('Forecasted_Count_of_Truck', 'max'),\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Round Avg_Trip ---\n",
    "#summary_df['Avg_Trip'] = np.ceil(summary_df['Avg_Trip']).astype(int)\n",
    "\n",
    "# --- Merge Route Info ---\n",
    "merged_df = pd.merge(summary_df, route_df, on=['Route_ID', 'Zone'], how='inner')\n",
    "\n",
    "# --- Calculate Number of Stops ---\n",
    "merged_df['No_of_Stops'] = merged_df['Destination Cities'].fillna('').apply(\n",
    "    lambda x: len(x.split(',')) if x else 0\n",
    ")\n",
    "\n",
    "# --- Final Column Order ---\n",
    "final_df = merged_df[[\n",
    "    'Zone', 'Route_ID', 'Truck_Type', 'Required_Trucks',\n",
    "    'Source City', 'Destination Cities', 'No_of_Stops', 'Distance_km'\n",
    "]]\n",
    "final_df.columns = [col.replace(\" \", \"_\") for col in final_df.columns]\n",
    "\n",
    "\n",
    "# --- Save as Zone-Wise CSVs into catalog ---\n",
    "spark_df = spark.createDataFrame(final_df)\n",
    "\n",
    "spark_df.write\\\n",
    "        .format(\"delta\")\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .saveAsTable(\"genai_catalog.genai_schema.zone_route_truck_requirements\")\n",
    "\n",
    "# Loop through each zone and write to Unity Catalog\n",
    "for zone in final_df['Zone'].unique():\n",
    "    zone_df = final_df[final_df['Zone'] == zone]\n",
    "    zone_file_path = os.path.join(output_dir, f\"{zone}.csv\")\n",
    "    zone_df.to_csv(zone_file_path, index=False)\n",
    "\n",
    "print(\"All zone-wise vendor files saved in: /dbfs/FileStore/zone_vendor_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a12162-d0a4-41e2-875d-f2dabfaa86bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--select * from genai_catalog.genai_schema.truck_forecast_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e57a613-4256-4d44-9096-aba0170ad782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8933268272595294,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Truck procurement Forecasting model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
